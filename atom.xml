<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>几米之家</title>
  
  <subtitle>Hold on to what we are, Hold on to your heart!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.hcrlp.com/"/>
  <updated>2018-12-17T06:17:17.927Z</updated>
  <id>http://www.hcrlp.com/</id>
  
  <author>
    <name>Jimmy Hua</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>The Learning Strategy of the CS231n</title>
    <link href="http://www.hcrlp.com/2018/12/14/The-Learning-Strategy-of-the-CS231n/"/>
    <id>http://www.hcrlp.com/2018/12/14/The-Learning-Strategy-of-the-CS231n/</id>
    <published>2018-12-14T07:05:43.000Z</published>
    <updated>2018-12-17T06:17:17.927Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h3><p>对于算法工程师，不同的人的认知角度都是不同的，我们通过下面三个知乎的高票回答帮助大家了解算法工程师到底需要做什么样的事，工业界需要什么样的能力<br>链接：<br>从今年校招来看，机器学习等算法岗位应届生超多，竞争激烈，未来 3-5 年机器学习相关就业会达到饱和吗？ - Cheeeen的回答 - 知乎<br> <a href="https://www.zhihu.com/question/66406672/answer/317489657" target="_blank" rel="noopener">https://www.zhihu.com/question/66406672/answer/317489657</a></p><p>2019 秋招的 AI 岗位竞争激烈吗？ - 王剑锋的回答 - 知乎<br> <a href="https://www.zhihu.com/question/286925266/answer/491117602" target="_blank" rel="noopener">https://www.zhihu.com/question/286925266/answer/491117602</a></p><p>论算法工程师首先是个工程师之深度学习在排序应用踩坑总结 - 吴海波的文章 - 知乎<br> <a href="https://zhuanlan.zhihu.com/p/44315278" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/44315278</a></p><h3 id="二、时间安排"><a href="#二、时间安排" class="headerlink" title="二、时间安排"></a>二、时间安排</h3><p>每周具体学习时间划分为4个部分:</p><blockquote><ol><li>部分安排周一到周二</li><li>部分安排在周四到周五</li><li>部分安排在周日</li><li>部分作业是是任何有空的时间自行完成，可以落后于学习进度</li><li>周三、周六休息</li></ol></blockquote><h3 id="三、课程资料"><a href="#三、课程资料" class="headerlink" title="三、课程资料"></a>三、课程资料</h3><p>课程主页： <a href="http://cs231n.stanford.edu" target="_blank" rel="noopener">http://cs231n.stanford.edu</a><br>英文笔记： <a href="http://cs231n.github.io" target="_blank" rel="noopener">http://cs231n.github.io</a><br>中文笔记： <a href="https://zhuanlan.zhihu.com/p/21930884" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21930884</a><br>课程视频： <a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">https://www.bilibili.com/video/av17204303</a><br>环境配置： <a href="https://github.com/sharedeeply/DeepLearning-StartKit" target="_blank" rel="noopener">https://github.com/sharedeeply/DeepLearning-StartKit</a><br>作业链接： [作业] <a href="https://github.com/sharedeeply/cs231n-camp/tree/master/assignment/assignment1" target="_blank" rel="noopener">https://github.com/sharedeeply/cs231n-camp/tree/master/assignment/assignment1</a><br>作业参考： <a href="https://github.com/sharedeeply/cs231n-assignment-solution" target="_blank" rel="noopener">https://github.com/sharedeeply/cs231n-assignment-solution</a><br>课程课件： <a href="https://github.com/sharedeeply/cs231n-camp/tree/master/slides" target="_blank" rel="noopener">https://github.com/sharedeeply/cs231n-camp/tree/master/slides</a></p><p>注册一个github账号：github.com<br>后续发布的一些project和exercise会在这个github下：<br> <a href="https://sharedeeply.github.io/cs231n-camp" target="_blank" rel="noopener">https://sharedeeply.github.io/cs231n-camp</a></p><h3 id="四、知识工具"><a href="#四、知识工具" class="headerlink" title="四、知识工具"></a>四、知识工具</h3><h4 id="数学工具"><a href="#数学工具" class="headerlink" title="数学工具"></a>数学工具</h4><p>cs229资料：<br>线性代数：<a href="http://web.stanford.edu/class/cs224n/readings/cs229-linalg.pdf" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224n/readings/cs229-linalg.pdf</a><br>概率论：<a href="http://101.96.10.44/web.stanford.edu/class/cs224n/readings/cs229-prob.pdf" target="_blank" rel="noopener">http://101.96.10.44/web.stanford.edu/class/cs224n/readings/cs229-prob.pdf</a><br>凸函数优化：<a href="http://101.96.10.43/web.stanford.edu/class/cs224n/readings/cs229-cvxopt.pdf" target="_blank" rel="noopener">http://101.96.10.43/web.stanford.edu/class/cs224n/readings/cs229-cvxopt.pdf</a><br>随机梯度下降算法：<a href="http://cs231n.github.io/optimization-1" target="_blank" rel="noopener">http://cs231n.github.io/optimization-1</a><br>中文资料：<br>机器学习中的数学基本知识：<a href="https://www.cnblogs.com/steven-yang/p/6348112.html" target="_blank" rel="noopener">https://www.cnblogs.com/steven-yang/p/6348112.html</a><br>统计学习方法：<a href="http://vdisk.weibo.com/s/vfFpMc1YgPOr" target="_blank" rel="noopener">http://vdisk.weibo.com/s/vfFpMc1YgPOr</a><br>大学数学课本从故纸堆里翻出来</p><h4 id="编程工具"><a href="#编程工具" class="headerlink" title="编程工具"></a>编程工具</h4><p>Python复习：<a href="http://web.stanford.edu/class/cs224n/lectures/python-review.pdf" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224n/lectures/python-review.pdf</a><br>PyTorch教程： <a href="https://cn.udacity.com/course/deep-learning-pytorch--ud188" target="_blank" rel="noopener">https://cn.udacity.com/course/deep-learning-pytorch--ud188</a><br>TensorFlow教程：<a href="https://github.com/aymericdamien/TensorFlow-Examples" target="_blank" rel="noopener">https://github.com/aymericdamien/TensorFlow-Examples</a><br>廖雪峰python3教程：<a href="https://www.liaoxuefeng.com/article/001432619295115c918a094d8954bd493037b03d27bf9a9000" target="_blank" rel="noopener">廖雪峰python3</a><br>github教程：<a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000</a><br>深度学习的学习路线：<a href="https://github.com/L1aoXingyu/Roadmap-of-DL-and-ML/blob/master/README_cn.md" target="_blank" rel="noopener">https://github.com/L1aoXingyu/Roadmap-of-DL-and-ML/blob/master/README_cn.md</a><br>开源深度学习课程：<a href="http://www.deeplearningweekly.com/blog/open-source-deep-learning-curriculum" target="_blank" rel="noopener">http://www.deeplearningweekly.com/blog/open-source-deep-learning-curriculum</a><br>mxnet/gluon教程： <a href="https://zh.gluon.ai" target="_blank" rel="noopener">https://zh.gluon.ai</a><br>知乎专栏：<a href="https://zhuanlan.zhihu.com/c_94953554" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/c_94953554</a><br>pytorch教程：<a href="https://github.com/L1aoXingyu/code-of-learn-deep-learning-with-pytorch" target="_blank" rel="noopener">https://github.com/L1aoXingyu/code-of-learn-deep-learning-with-pytorch</a></p><h3 id="五、学习计划"><a href="#五、学习计划" class="headerlink" title="五、学习计划"></a>五、学习计划</h3><h4 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1:"></a>Week 1:</h4><ul><li><p>第1部分学习任务：<br>1听深度学习绪论+0基础一小时完成一场比赛PPT<br>学习时长：10/30<br>任务详解：视频1主要是介绍深度学习的一些应用案例，第二个是完成一次kaggle比赛的流程<br>2了解计算机视觉综述，历史背景和课程大纲<br>学习时长：10/30<br>slides: <a href="https://github.com/sharedeeply/cs231n-camp/blob/master/slides/cs231n_2018_lecture01.pdf" target="_blank" rel="noopener">lecture01</a><br>观看视频 p1, p2 和 p3<br>课程视频： <a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">https://www.bilibili.com/video/av17204303</a></p></li><li><p>第2部分学习任务：<br>1学习数据驱动的方法, 理解 KNN 算法，初步学习线性分类器<br>slides: <a href="https://github.com/sharedeeply/cs231n-camp/blob/master/slides/cs231n_2018_lecture01.pdf" target="_blank" rel="noopener">lecture02</a><br>观看视频 p4 p5 和 p6：<a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">https://www.bilibili.com/video/av17204303</a><br>学习 图像分类笔记上：<a href="https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit</a><br>学习 图像分类笔记下：<a href="https://zhuanlan.zhihu.com/p/20900216" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/20900216</a><br>学习 线性分类笔记上：<a href="https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit</a><br>学习时长：11/1—11/2</p></li><li><p>第3部分学习任务：<br>1掌握本门课 python 编程的基本功<br>阅读 python 和 numpy 教程：<a href="https://zhuanlan.zhihu.com/p/20878530?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/20878530?refer=intelligentunit</a><br>代码：<a href="https://zhuanlan.zhihu.com/p/20878530?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/20878530?refer=intelligentunit</a><br>学习时长：11/4</p></li><li><p>第4部分作业：(热身)写一个矩阵的类，实现矩阵乘法，只能使用 python 的类(class)和列表(list)<br>完成assignment1 中的 knn.ipynb<br>作业链接： <a href="https://github.com/sharedeeply/cs231n-camp/tree/master/assignment/assignment1" target="_blank" rel="noopener">作业</a></p></li></ul><hr><h4 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2:"></a>Week 2:</h4><ul><li><p>第1部分学习任务：<br>1深入理解线性分类器的原理<br>slides: <a href="https://github.com/sharedeeply/cs231n-camp/blob/master/slides/cs231n_2018_lecture03.pdf" target="_blank" rel="noopener">lecture03</a><br>观看视频 p7：<a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">https://www.bilibili.com/video/av17204303</a><br>学习 线性分类笔记中：<a href="https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit</a><br>学习 线性分类笔记下：<a href="https://zhuanlan.zhihu.com/p/21102293" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21102293</a><br>学习时长：11/5—11/6</p></li><li><p>第2部分学习任务：<br>1学习损失函数以及梯度下降的相关知识<br>slides: <a href="https://github.com/sharedeeply/cs231n-camp/blob/master/slides/cs231n_2018_lecture03.pdf" target="_blank" rel="noopener">lecture03</a><br>观看视频 p8：<a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">https://www.bilibili.com/video/av17204303</a><br>学习 最优化笔记：<a href="https://zhuanlan.zhihu.com/p/21360434?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21360434?refer=intelligentunit</a><br>学习时长：11/8—11/9</p></li><li><p>第3部分学习任务：<br>1掌握矩阵求导的基本方法<br>根据资料，学习矩阵求导的基本技巧，看多少内容取决于个人需要：<a href="https://zhuanlan.zhihu.com/p/25063314" target="_blank" rel="noopener">矩阵求导</a><br>学习时长：11/11</p></li><li><p>第4部分作业：<br>(1)简述 KNN 和线性分类器的优劣<br>(2)完成assignment1 中 svm.ipynb<br>作业链接： <a href="https://github.com/sharedeeply/cs231n-camp/tree/master/assignment/assignment1" target="_blank" rel="noopener">作业</a></p></li></ul><hr><h4 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3:"></a>Week 3:</h4><ul><li><p>第1部分学习任务：<br>1学习掌握深度学习的基石: 反向传播算法<br>slides: <a href="https://github.com/sharedeeply/cs231n-camp/blob/master/slides/cs231n_2018_lecture04.pdf" target="_blank" rel="noopener">lecture04</a><br>观看视频 p9：<a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">https://www.bilibili.com/video/av17204303</a><br>学习反向传播算法的笔记：<a href="https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit</a><br>学习时长：11/12—11/13</p></li><li><p>第2部分学习任务：<br>1理解神经网络的结构和原理<br>slides: <a href="https://github.com/sharedeeply/cs231n-camp/blob/master/slides/cs231n_2018_lecture04.pdf" target="_blank" rel="noopener">lecture04</a><br>观看视频 p10：<a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">https://www.bilibili.com/video/av17204303</a><br>学习时长：11/15—11/16</p></li><li><p>第3部分学习任务：<br>1深入理解反向传播算法<br>阅读反向传播算法的数学补充：<a href="http://cs231n.stanford.edu/handouts/derivatives.pdf" target="_blank" rel="noopener">http://cs231n.stanford.edu/handouts/derivatives.pdf</a><br>例子：<a href="http://cs231n.stanford.edu/handouts/linear-backprop.pdf" target="_blank" rel="noopener">http://cs231n.stanford.edu/handouts/linear-backprop.pdf</a><br>学习时长：11/18</p></li><li><p>第4部分作业：<br>完成 assignment1 中的 softmax.ipynb<br>完成 assignment1 中的 two_layer_net.ipynb<br>作业链接： <a href="https://github.com/sharedeeply/cs231n-camp/tree/master/assignment/assignment1" target="_blank" rel="noopener">作业</a></p></li></ul><hr><h4 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4:"></a>Week 4:</h4><ul><li><p>第1部分学习任务：<br>1掌握 PyTorch 中的基本操作<br>学习 pytorch 的入门基础：<a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html" target="_blank" rel="noopener">https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html</a><br>学习时长：11/19—11/20</p></li><li><p>第2部分学习任务：<br>1了解 kaggle 比赛的流程，并完成第一次的成绩提交<br>了解比赛房价预测：<a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" target="_blank" rel="noopener">https://www.kaggle.com/c/house-prices-advanced-regression-techniques</a><br>学习模板代码：<a href="https://github.com/L1aoXingyu/kaggle-house-price" target="_blank" rel="noopener">https://github.com/L1aoXingyu/kaggle-house-price</a><br>学习时长：11/22—11/23</p></li><li><p>第3部分学习任务：<br>1学习 PyTorch 中的数据读取<br>学习官方教程：<a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html" target="_blank" rel="noopener">https://pytorch.org/tutorials/beginner/data_loading_tutorial.html</a><br>学习中文笔记：<a href="https://l1aoxingyu.github.io/2017/10/23/PyTorch%E5%AE%9E%E7%8E%B0%E8%87%AA%E7%94%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96" target="_blank" rel="noopener">笔记</a></p></li></ul><p>学习时长：11/25</p><ul><li>第4部分作业：<br>1完成 assignment1 中的 features.ipynb<br>提交方式：发送到训练营公共邮箱<br>2修改房价预测的代码，在训练营里打卡提交 kaggle 的成绩<br>作业链接： <a href="https://github.com/sharedeeply/cs231n-camp/tree/master/assignment/assignment1" target="_blank" rel="noopener">作业</a></li></ul><hr><h4 id="Week-5"><a href="#Week-5" class="headerlink" title="Week 5:"></a>Week 5:</h4><ul><li><p>第1部分学习任务：<br>1理解 CNN 中的卷积<br>slides: <a href="https://github.com/sharedeeply/cs231n-camp/blob/master/slides/cs231n_2018_lecture05.pdf" target="_blank" rel="noopener">lecture05</a><br>观看视频 p11, p12：<a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">https://www.bilibili.com/video/av17204303</a><br>学习时长：11/26—11/27</p></li><li><p>第2部分学习任务：<br>1理解 CNN 中的 pooling<br>slides: <a href="https://github.com/sharedeeply/cs231n-camp/blob/master/slides/cs231n_2018_lecture05.pdf" target="_blank" rel="noopener">lecture05</a><br>观看视频 p13：<a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">https://www.bilibili.com/video/av17204303</a><br>学习卷积神经网络笔记：<a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit</a><br>学习时长：11/29—11/30</p></li><li><p>第3部分学习任务：<br>1完成 CNN 的第一个应用练习，人脸关键点检测<br>阅读 facial keypoint 小项目：<a href="https://github.com/udacity/P1_Facial_Keypoints" target="_blank" rel="noopener">https://github.com/udacity/P1_Facial_Keypoints</a><br>参考代码：<a href="https://github.com/L1aoXingyu/P1_Facial_Keypoints" target="_blank" rel="noopener">https://github.com/L1aoXingyu/P1_Facial_Keypoints</a><br>学习时长：12/02</p></li><li><p>第4部分作业：<br>1完成 assignment2 中 FullyConnectedNets.ipynb<br>提交方式：发送到训练营公共邮箱<br>2思考一下卷积神经网络对比传统神经网络的优势在哪里？为什么更适合处理图像问题，在训练营里打卡提交<br>作业链接： <a href="https://github.com/sharedeeply/cs231n-camp/tree/master/assignment/assignment1" target="_blank" rel="noopener">作业</a></p></li></ul><hr><h4 id="Week-6"><a href="#Week-6" class="headerlink" title="Week 6:"></a>Week 6:</h4><ul><li><p>第1部分学习任务：<br>1理解激活函数，权重初始化，batchnorm 对网络训练的影响<br>slides: <a href="https://github.com/sharedeeply/cs231n-camp/blob/master/slides/cs231n_2018_lecture06.pdf" target="_blank" rel="noopener">lecture06</a><br>观看视频 p14：<a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">https://www.bilibili.com/video/av17204303</a><br>学习神经网络笔记1：<a href="https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit</a><br>学习时长：12/03—12/04</p></li><li><p>第2部分学习任务：<br>1深入理解 BatchNormalization<br>slides: <a href="https://github.com/sharedeeply/cs231n-camp/blob/master/slides/cs231n_2018_lecture06.pdf" target="_blank" rel="noopener">lecture06</a><br>观看视频 p15：<a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">https://www.bilibili.com/video/av17204303</a><br>学习神经网络笔记2：<a href="https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit</a><br>学习时长：12/06—12/07</p></li><li><p>第3部分学习任务：<br>1总结回顾和理解深度学习中 normalize 的技巧<br>阅读文章 深度学习中的 normalization 方法：<a href="https://zhuanlan.zhihu.com/p/33173246" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33173246</a><br>学习时长：12/09</p></li><li><p>第4部分作业：<br>完成 assignment2 中 BatchNormalization.ipynb<br>完成 assignment2 中 Dropout.ipynb<br>提交方式：发送到训练营公共邮箱<br>作业链接： <a href="https://github.com/sharedeeply/cs231n-camp/tree/master/assignment/assignment1" target="_blank" rel="noopener">作业</a></p></li></ul><hr><h4 id="Week-7"><a href="#Week-7" class="headerlink" title="Week 7:"></a>Week 7:</h4><ul><li><p>第1部分学习任务：<br>1理解更 fancy 的优化方法，更多的 normalize 以及正则化和迁移学习对网络训练的影响<br>slides: <a href="https://github.com/sharedeeply/cs231n-camp/blob/master/slides/cs231n_2018_lecture07.pdf" target="_blank" rel="noopener">lecture07</a><br>观看视频 p16，p17，p18：<a href="https://www.bilibili.com/video/av17204303" target="_blank" rel="noopener">https://www.bilibili.com/video/av17204303</a><br>学习神经网络笔记3：<a href="https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit</a><br>学习时长：12/10—12/11</p></li><li><p>第2部分学习任务：<br>1了解第二次的 kaggle 比赛 cifar10 分类<br>报名 cifar10 比赛：<a href="https://www.kaggle.com/c/cifar-10" target="_blank" rel="noopener">https://www.kaggle.com/c/cifar-10</a><br>学习模板代码：<a href="https://github.com/L1aoXingyu/kaggle-cifar10" target="_blank" rel="noopener">https://github.com/L1aoXingyu/kaggle-cifar10</a><br>学习时长：12/13—12/14</p></li><li><p>第4部分作业：<br>1完成 assignment2 中 ConvolutionNetworks.ipynb<br>提交方式：发送到训练营公共邮箱<br>2修改 cifar10 的网络结构，在训练营里打卡提交 kaggle 成绩<br>作业链接： <a href="https://github.com/sharedeeply/cs231n-camp/tree/master/assignment/assignment1" target="_blank" rel="noopener">作业</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一、前言&quot;&gt;&lt;a href=&quot;#一、前言&quot; class=&quot;headerlink&quot; title=&quot;一、前言&quot;&gt;&lt;/a&gt;一、前言&lt;/h3&gt;&lt;p&gt;对于算法工程师，不同的人的认知角度都是不同的，我们通过下面三个知乎的高票回答帮助大家了解算法工程师到底需要做什么样的事，工业
      
    
    </summary>
    
      <category term="Computer Vision" scheme="http://www.hcrlp.com/categories/Computer-Vision/"/>
    
    
      <category term="cs231n" scheme="http://www.hcrlp.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>Yolo2 训练自己数据集</title>
    <link href="http://www.hcrlp.com/2018/12/10/Yolo2-%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <id>http://www.hcrlp.com/2018/12/10/Yolo2-训练自己数据集/</id>
    <published>2018-12-10T10:36:03.000Z</published>
    <updated>2018-12-17T06:15:08.663Z</updated>
    
    <content type="html"><![CDATA[<p>####1. 添加数据分类的各个类别名称文 data/rabbit.names:</p><p><a href="https://i.loli.net/2018/12/10/5c0e407334b25.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2018/12/10/5c0e407334b25.png" alt="1.png"></a></p><p>####2. 添加配置文件/cfg/rabbit.data，并且修改自己需要的类别和训练数据集：</p><p><a href="https://i.loli.net/2018/12/10/5c0e407341624.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2018/12/10/5c0e407341624.png" alt="2.png"></a></p><p>####3. 修改网络配置 /cfg/yolov2-tiny-voc.cfg:</p><p><a href="https://i.loli.net/2018/12/10/5c0e40733ea05.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2018/12/10/5c0e40733ea05.png" alt="3.png"></a></p><p><a href="https://i.loli.net/2018/12/10/5c0e40735f4a6.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2018/12/10/5c0e40735f4a6.png" alt="4.png"></a></p><p>####4. 修改 Makefile 改成GPU训练：</p><p><a href="https://i.loli.net/2018/12/10/5c0e4073649c9.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2018/12/10/5c0e4073649c9.png" alt="5.png"></a></p><p>####5. 运行命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">* 训练：./darknet detector train cfg/rabbit.data cfg/yolov2-tiny.cfg darknet19_448.conv.23</span><br><span class="line"></span><br><span class="line">* 测试：./darknet detector <span class="built_in">test</span> cfg/rabbit.data cfg/yolov2-tiny.cfg backup/tiny-yolo-1/yolov2-tiny_50000.weights data/pic_1350.png</span><br><span class="line"></span><br><span class="line">* recall：./darknet detector recall cfg/rabbit.data cfg/yolov2-tiny.cfg backup/tiny-yolo-1/yolov2-tiny_50000.weights</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;####1. 添加数据分类的各个类别名称文 data/rabbit.names:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://i.loli.net/2018/12/10/5c0e407334b25.png&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
      
    
    </summary>
    
      <category term="Computer Vision" scheme="http://www.hcrlp.com/categories/Computer-Vision/"/>
    
    
      <category term="yolo2" scheme="http://www.hcrlp.com/tags/yolo2/"/>
    
  </entry>
  
  <entry>
    <title>语义分割-PSPNET</title>
    <link href="http://www.hcrlp.com/2018/11/29/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2-PSPNET/"/>
    <id>http://www.hcrlp.com/2018/11/29/语义分割-PSPNET/</id>
    <published>2018-11-29T08:19:30.000Z</published>
    <updated>2018-12-05T10:36:25.532Z</updated>
    
    <content type="html"><![CDATA[<p><strong> PSPNET:</strong> <a href="https://arxiv.org/abs/1612.01105" target="_blank" rel="noopener">Pyramid Scene Parsing Network</a></p><p><strong>From :</strong> CVPR 2017(IEEE Conference on Computer Vision and Pattern Recognition)</p><p><strong>代码：</strong></p><ul><li><p><a href="https://github.com/Vladkryvoruchko/PSPNet-Keras-tensorflow" target="_blank" rel="noopener">PSPnet-Keras-TensorFlow</a></p></li><li><p><a href="https://github.com/Lextal/pspnet-pytorch" target="_blank" rel="noopener">PSPnet-Pytorch</a></p></li></ul><p><strong>效果：</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/11679057-cb0abf4f5eaf8f4c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" width="700"></p><p><strong>对比传统方法：</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/11679057-59d0704d1924bf7a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" width="700"></p><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>本文提出的金字塔池化模块( pyramid pooling module)能够<strong>聚合不同区域的上下文信息</strong>,从而提高获取全局信息的能力。实验表明这样的先验表示(即指代PSP这个结构)是有效的，在多个数据集上展现了优良的效果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt; PSPNET:&lt;/strong&gt; &lt;a href=&quot;https://arxiv.org/abs/1612.01105&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Pyramid Scene Parsing Network&lt;/a&gt;&lt;/p&gt;
      
    
    </summary>
    
      <category term="Segmentation" scheme="http://www.hcrlp.com/categories/Segmentation/"/>
    
    
      <category term="Paper" scheme="http://www.hcrlp.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch 参数初始化</title>
    <link href="http://www.hcrlp.com/2018/11/23/Pytorch-%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96/"/>
    <id>http://www.hcrlp.com/2018/11/23/Pytorch-参数初始化/</id>
    <published>2018-11-23T02:13:51.000Z</published>
    <updated>2018-11-23T02:41:37.732Z</updated>
    
    <content type="html"><![CDATA[<p><strong> Pytorch 提供了很多不同的参数初始化函数：</strong></p><ul><li>torch.nn.init.constant_(tensor,val)</li><li>torch.nn.init.normal_(tensor,mean=0,std=1)</li><li>torch.nn.init.xavier_uniform_(tensor,gain=1)</li><li>更多的可以参考：<a href="http://pytorch.org/docs/nn.html#torch-nn-init" target="_blank" rel="noopener">http://pytorch.org/docs/nn.html#torch-nn-init</a></li></ul><p>注意上面的初始化函数的参数tensor，虽然写的是tensor，但是也可以是Variable类型的。而神经网络的参数类型Parameter是Variable类的子类，所以初始化函数可以直接作用于神经网络参数。</p><p>示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>)</span><br><span class="line">init.xavier_uniform_(self.conv1.weight)</span><br><span class="line">init.constant_(self.conv1.bias, <span class="number">0.1</span>)</span><br></pre></td></tr></table></figure></p><p>上面的语句是对网络的某一层参数进行初始化。如何对整个网络的参数进行初始化定制呢？<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xavier</span><span class="params">(parm)</span>:</span></span><br><span class="line">    init.xavier_normal_(parm)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weights_init</span><span class="params">(m)</span>:</span></span><br><span class="line">    classname=m.__class__.__name__</span><br><span class="line">    <span class="keyword">if</span> classname.find(<span class="string">'Conv'</span>) != <span class="number">-1</span>:</span><br><span class="line">        xavier(m.weight.data)</span><br><span class="line">        xavier(m.bias.data)</span><br><span class="line">net = Net()</span><br><span class="line">net.apply(weights_init) <span class="comment">#apply函数会递归地搜索网络内的所有module并把参数表示的函数应用到所有的module上</span></span><br></pre></td></tr></table></figure></p><p>不建议访问以下划线为前缀的成员，他们是内部的，如果有改变不会通知用户。更推荐的一种方法是检查某个module是否是某种类型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xavier</span><span class="params">(parm)</span>:</span></span><br><span class="line">    init.xavier_normal_(parm)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weights_init</span><span class="params">(m)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(m, nn.Conv2d):</span><br><span class="line">        xavier(m.weight.data)</span><br><span class="line">        xavier(m.bias.data)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt; Pytorch 提供了很多不同的参数初始化函数：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;torch.nn.init.constant_(tensor,val)&lt;/li&gt;
&lt;li&gt;torch.nn.init.normal_(tensor,mean=0,
      
    
    </summary>
    
      <category term="Deep Learning" scheme="http://www.hcrlp.com/categories/Deep-Learning/"/>
    
    
      <category term="Pytorch" scheme="http://www.hcrlp.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>CS231n学习笔记一：K近邻和图像分类</title>
    <link href="http://www.hcrlp.com/2018/11/08/CS231n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80%EF%BC%9AK%E8%BF%91%E9%82%BB%E5%92%8C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    <id>http://www.hcrlp.com/2018/11/08/CS231n学习笔记一：K近邻和图像分类/</id>
    <published>2018-11-08T10:29:59.000Z</published>
    <updated>2018-12-17T06:15:18.945Z</updated>
    
    <content type="html"><![CDATA[<h3 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h3><h4 id="1-概述："><a href="#1-概述：" class="headerlink" title="1. 概述："></a>1. 概述：</h4><p><strong>目标：</strong>所谓图像分类问题，就是已有固定的分类标签集合，然后对于输入的图像，从分类标签集合中找出一个分类标签，最后把分类标签分配给该输入图像。虽然看起来挺简单的，但这可是计算机视觉领域的核心问题之一，并且有着各种各样的实际应用。在后面的课程中，我们可以看到计算机视觉领域中很多看似不同的问题（比如物体检测和分割），都可以被归结为图像分类问题。</p><p><strong>例子：</strong>以下图为例，图像分类模型读取该图片，并生成该图片属于集合 {cat, dog, hat, mug}中各个标签的概率。需要注意的是，对于计算机来说，图像是一个由数字组成的巨大的3维数组。在这个例子中，猫的图像大小是宽248像素，高400像素，有3个颜色通道，分别是红、绿和蓝（简称RGB）。如此，该图像就包含了248X400X3=297600个数字，每个数字都是在范围0-255之间的整型，其中0表示全黑，255表示全白。我们的任务就是把这些上百万的数字变成一个简单的标签，比如“猫”。</p><p><img src="https://pic2.zhimg.com/80/baab9e4b97aceb77ec70abeda6be022d_hd.png" width="600"></p><h4 id="2-困难和挑战："><a href="#2-困难和挑战：" class="headerlink" title="2. 困难和挑战："></a>2. 困难和挑战：</h4><p>对于人来说，识别出一个像“猫”一样视觉概念是简单至极的，然而从计算机视觉算法的角度来看就值得深思了。我们在下面列举了计算机视觉算法在图像识别方面遇到的一些困难，要记住图像是以3维数组来表示的，数组中的元素是亮度值。</p><ul><li>视角变化（Viewpoint variation）：同一个物体，摄像机可以从多个角度来展现。</li><li>大小变化（Scale variation）：物体可视的大小通常是会变化的（不仅是在图片中，在真实世界中大小也是变化的）。</li><li>形变（Deformation）：很多东西的形状并非一成不变，会有很大变化。</li><li>遮挡（Occlusion）：目标物体可能被挡住。有时候只有物体的一小部分（可以小到几个像素）是可见的。</li><li>光照条件（Illumination conditions）：在像素层面上，光照的影响非常大。</li><li>背景干扰（Background clutter）：物体可能混入背景之中，使之难以被辨认。</li><li>类内差异（Intra-class variation）：一类物体的个体之间的外形差异很大，比如椅子。这一类物体有许多不同的对象，每个都有自己的外形。<br>面对以上所有变化及其组合，好的图像分类模型能够在维持分类结论稳定的同时，保持对类间差异足够敏感。</li></ul><p><img src="https://pic2.zhimg.com/80/1ee9457872f773d671dd5b225647ef45_hd.jpg" width="600"></p><h3 id="Nearest-Neighbor分类器"><a href="#Nearest-Neighbor分类器" class="headerlink" title="Nearest Neighbor分类器"></a>Nearest Neighbor分类器</h3><h4 id="L1-距离："><a href="#L1-距离：" class="headerlink" title="L1 距离："></a>L1 距离：</h4><p>针对CIFAR-10数据集，图片都是32x32x3的像素块，最简单的方法就是逐个像素比较，最后将差异值全部加起来。换句话说，就是将两张图片先转化为两个向量I_1和I_2，然后计算他们的L1距离：</p><p><img src="http://www.zhihu.com/equation?tex=%5Cdisplaystyle+d_1%28I_1%2CI_2%29%3D%5Csum_p%7CI%5Ep_1-I%5Ep_2%7C\"></p><p>可以通过下面的流程更清楚表示：</p><p><img src="https://pic2.zhimg.com/80/95cfe7d9efb83806299c218e0710a6c5_hd.jpg" width="600"></p><p>下面，让我们看看如何用代码来实现这个分类器。首先，我们将CIFAR-10的数据加载到内存中，并分成4个数组：训练数据和标签，测试数据和标签。在下面的代码中，Xtr（大小是50000x32x32x3）存有训练集中所有的图像，Ytr是对应的长度为50000的1维数组，存有图像对应的分类标签（从0到9）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Xtr, Ytr, Xte, Yte = load_CIFAR10(<span class="string">'data/cifar10/'</span>) <span class="comment"># a magic function we provide</span></span><br><span class="line"><span class="comment"># flatten out all images to be one-dimensional</span></span><br><span class="line">Xtr_rows = Xtr.reshape(Xtr.shape[<span class="number">0</span>], <span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>) <span class="comment"># Xtr_rows becomes 50000 x 3072</span></span><br><span class="line">Xte_rows = Xte.reshape(Xte.shape[<span class="number">0</span>], <span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>) <span class="comment"># Xte_rows becomes 10000 x 3072</span></span><br></pre></td></tr></table></figure></p><p>现在我们得到所有的图像数据，并且把他们拉长成为行向量了。接下来展示如何训练并评价一个分类器：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nn = NearestNeighbor() <span class="comment"># create a Nearest Neighbor classifier class</span></span><br><span class="line">nn.train(Xtr_rows, Ytr) <span class="comment"># train the classifier on the training images and labels</span></span><br><span class="line">Yte_predict = nn.predict(Xte_rows) <span class="comment"># predict labels on the test images</span></span><br><span class="line"><span class="comment"># and now print the classification accuracy, which is the average number</span></span><br><span class="line"><span class="comment"># of examples that are correctly predicted (i.e. label matches)</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'accuracy: %f'</span> % ( np.mean(Yte_predict == Yte) )</span><br></pre></td></tr></table></figure></p><p>作为评价标准，我们常常使用准确率，它描述了我们预测正确的得分。请注意以后我们实现的所有分类器都需要有这个API：train(X, y)函数。该函数使用训练集的数据和标签来进行训练。从其内部来看，类应该实现一些关于标签和标签如何被预测的模型。这里还有个predict(X)函数，它的作用是预测输入的新数据的分类标签。现在还没介绍分类器的实现，下面就是使用L1距离的Nearest Neighbor分类器的实现套路：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NearestNeighbor</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">    <span class="string">""" X is N x D where each row is an example. Y is 1-dimension of size N """</span></span><br><span class="line">    <span class="comment"># the nearest neighbor classifier simply remembers all the training data</span></span><br><span class="line">    self.Xtr = X</span><br><span class="line">    self.ytr = y</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></span><br><span class="line">    <span class="string">""" X is N x D where each row is an example we wish to predict label for """</span></span><br><span class="line">    num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># lets make sure that the output type matches the input type</span></span><br><span class="line">    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loop over all test rows</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_test):</span><br><span class="line">      <span class="comment"># find the nearest training image to the i'th test image</span></span><br><span class="line">      <span class="comment"># using the L1 distance (sum of absolute value differences)</span></span><br><span class="line">      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = <span class="number">1</span>)</span><br><span class="line">      min_index = np.argmin(distances) <span class="comment"># get the index with smallest distance</span></span><br><span class="line">      Ypred[i] = self.ytr[min_index] <span class="comment"># predict the label of the nearest example</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Ypred</span><br></pre></td></tr></table></figure></p><h4 id="L2-距离："><a href="#L2-距离：" class="headerlink" title="L2 距离："></a>L2 距离：</h4><p>L2的距离公式为：  <img src="http://www.zhihu.com/equation?tex=%5Cdisplaystyle+d_2%28I_1%2CI_2%29%3D%5Csqrt%7B+%5Csum_p%28I%5Ep_1-I%5Ep_2%29%5E2%7D">,所以我们在Numpy中，我们只需要替换上面代码中的1行代码就行：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = <span class="number">1</span>))</span><br></pre></td></tr></table></figure></p><h3 id="k-Nearest-Neighbor分类器"><a href="#k-Nearest-Neighbor分类器" class="headerlink" title="k-Nearest Neighbor分类器"></a>k-Nearest Neighbor分类器</h3><h4 id="概念："><a href="#概念：" class="headerlink" title="概念："></a>概念：</h4><p>相对于传统的 NN 方法，只找最相近的那1个图片的标签，我们也可以找最相似的k个图片的标签，然后让他们针对测试图片进行投票，最后把票数最高的标签作为对测试图片的预测。所以当k=1的时候，k-Nearest Neighbor分类器就是Nearest Neighbor分类器。从直观感受上就可以看到，更高的k值可以让分类的效果更平滑，使得分类器对于异常值更有抵抗力。</p><p><img src="https://pic3.zhimg.com/80/51aef845faa10195e33bdd4657592f86_hd.jpg" width="600"></p><p><strong><em>PS:</em></strong> 在NN分类器中，异常的数据点（比如：在蓝色区域中的绿点）制造出一个不正确预测的孤岛。5-NN分类器将这些不规则都平滑了，使得它针对测试数据的泛化（generalization）能力更好（例子中未展示）。注意，5-NN中也存在一些灰色区域，这些区域是因为近邻标签的最高票数相同导致的（比如：2个邻居是红色，2个邻居是蓝色，还有1个是绿色）。</p><h3 id="验证数据集"><a href="#验证数据集" class="headerlink" title="验证数据集"></a>验证数据集</h3><p>当你在设计机器学习算法的时候，应该把测试集看做非常珍贵的资源，不到最后一步，绝不使用它。如果你使用测试集来调优，而且算法看起来效果不错，那么真正的危险在于：算法实际部署后，性能可能会远低于预期。这种情况，称之为算法对测试集过拟合。从另一个角度来说，如果使用测试集来调优，实际上就是把测试集当做训练集，由测试集训练出来的算法再跑测试集，自然性能看起来会很好。这其实是过于乐观了，实际部署起来效果就会差很多。所以，最终测试的时候再使用测试集，可以很好地近似度量你所设计的分类器的泛化性能</p><blockquote><p>测试数据集只使用一次，即在训练完成后评价最终的模型时使用。</p></blockquote><p>思路是：从训练集中取出一部分数据用来调优，我们称之为验证集（validation set）。以CIFAR-10为例，我们可以用49000个图像作为训练集，用1000个图像作为验证集。验证集其实就是作为假的测试集来调优。下面就是代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># assume we have Xtr_rows, Ytr, Xte_rows, Yte as before</span></span><br><span class="line"><span class="comment"># recall Xtr_rows is 50,000 x 3072 matrix</span></span><br><span class="line">Xval_rows = Xtr_rows[:<span class="number">1000</span>, :] <span class="comment"># take first 1000 for validation</span></span><br><span class="line">Yval = Ytr[:<span class="number">1000</span>]</span><br><span class="line">Xtr_rows = Xtr_rows[<span class="number">1000</span>:, :] <span class="comment"># keep last 49,000 for train</span></span><br><span class="line">Ytr = Ytr[<span class="number">1000</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># find hyperparameters that work best on the validation set</span></span><br><span class="line">validation_accuracies = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># use a particular value of k and evaluation on validation data</span></span><br><span class="line">  nn = NearestNeighbor()</span><br><span class="line">  nn.train(Xtr_rows, Ytr)</span><br><span class="line">  <span class="comment"># here we assume a modified NearestNeighbor class that can take a k as input</span></span><br><span class="line">  Yval_predict = nn.predict(Xval_rows, k = k)</span><br><span class="line">  acc = np.mean(Yval_predict == Yval)</span><br><span class="line">  <span class="keyword">print</span> <span class="string">'accuracy: %f'</span> % (acc,)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># keep track of what works on the validation set</span></span><br><span class="line">  validation_accuracies.append((k, acc))</span><br></pre></td></tr></table></figure></p><p>程序结束后，我们会作图分析出哪个k值表现最好，然后用这个k值来跑真正的测试集，并作出对算法的评价。</p><blockquote><p>把训练集分成训练集和验证集。使用验证集来对所有超参数调优。最后只在测试集上跑一次并报告结果。</p></blockquote><p>—————————————————————————————————————————<br><strong>交叉验证：</strong>有时候，训练集数量较小（因此验证集的数量更小），人们会使用一种被称为交叉验证的方法，这种方法更加复杂些。还是用刚才的例子，如果是交叉验证集，我们就不是取1000个图像，而是将训练集平均分成5份，其中4份用来训练，1份用来验证。然后我们循环着取其中4份来训练，其中1份来验证，最后取所有5次验证结果的平均值作为算法验证结果。</p><p><img src="https://pic1.zhimg.com/80/6a3ceec60cc0a379b4939c37ee3e89e8_hd.png" width="600"><br>这就是5份交叉验证对k值调优的例子。针对每个k值，得到5个准确率结果，取其平均值，然后对不同k值的平均表现画线连接。本例中，当k=7的时算法表现最好（对应图中的准确率峰值）。如果我们将训练集分成更多份数，直线一般会更加平滑（噪音更少）。</p><p>—————————————————————————————————————————</p><p>实际应用。在实际情况下，人们不是很喜欢用交叉验证，主要是因为它会耗费较多的计算资源。一般直接把训练集按照50%-90%的比例分成训练集和验证集。但这也是根据具体情况来定的：如果超参数数量多，你可能就想用更大的验证集，而验证集的数量不够，那么最好还是用交叉验证吧。至于分成几份比较好，一般都是分成3、5和10份。</p><p><img src="https://pic1.zhimg.com/80/cc88207c6c3c5e91df8b6367368f6450_hd.jpg" width="600"></p><p>常用的数据分割模式。给出训练集和测试集后，训练集一般会被均分。这里是分成5份。前面4份用来训练，黄色那份用作验证集调优。如果采取交叉验证，那就各份轮流作为验证集。最后模型训练完毕，超参数都定好了，让模型跑一次（而且只跑一次）测试集，以此测试结果评价算法。</p><p>—————————————————————————————————————————</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p><strong>简要说来：</strong></p><ol><li>介绍了图像分类问题。在该问题中，给出一个由被标注了分类标签的图像组成的集合，要求算法能预测没有标签的图像的分类标签，并根据算法预测准确率进行评价。</li><li>介绍了一个简单的图像分类器：最近邻分类器(Nearest Neighbor classifier)。分类器中存在不同的超参数(比如k值或距离类型的选取)，要想选取好的超参数不是一件轻而易举的事。</li><li>选取超参数的正确方法是：将原始训练集分为训练集和验证集，我们在验证集上尝试不同的超参数，最后保留表现最好那个。</li><li>如果训练数据量不够，使用交叉验证方法，它能帮助我们在选取最优超参数的时候减少噪音。</li><li>一旦找到最优的超参数，就让算法以该参数在测试集跑且只跑一次，并根据测试结果评价算法。</li><li>最近邻分类器能够在CIFAR-10上得到将近40%的准确率。该算法简单易实现，但需要存储所有训练数据，并且在测试的时候过于耗费计算能力。</li><li>最后，我们知道了仅仅使用L1和L2范数来进行像素比较是不够的，图像更多的是按照背景和颜色被分类，而不是语义主体分身。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;图像分类&quot;&gt;&lt;a href=&quot;#图像分类&quot; class=&quot;headerlink&quot; title=&quot;图像分类&quot;&gt;&lt;/a&gt;图像分类&lt;/h3&gt;&lt;h4 id=&quot;1-概述：&quot;&gt;&lt;a href=&quot;#1-概述：&quot; class=&quot;headerlink&quot; title=&quot;1. 概述：&quot;
      
    
    </summary>
    
      <category term="Computer Vision" scheme="http://www.hcrlp.com/categories/Computer-Vision/"/>
    
    
      <category term="笔记" scheme="http://www.hcrlp.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>深度学习环境搭建</title>
    <link href="http://www.hcrlp.com/2018/10/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>http://www.hcrlp.com/2018/10/31/深度学习环境搭建/</id>
    <published>2018-10-31T02:56:23.000Z</published>
    <updated>2018-12-17T06:15:32.859Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DeepLearning-Environment"><a href="#DeepLearning-Environment" class="headerlink" title="DeepLearning-Environment"></a>DeepLearning-Environment</h1><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><p>Python 能够使用各种各样的开发环境，这里我们强烈推荐使用 Anaconda 来进行Python 环境的管理，当然如果你有自己偏好的 Python 环境管理方式，你完全可以使用自己更喜欢的方式。</p><p>1.登录 Anaconda 的官网 <a href="www.anaconda.com">www.anaconda.com</a>，选择下载</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fp8zfmxb5ej30lt0bb0tc.jpg" width="700"></p><p>2.选择对应的操作系统</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fp8zgyn21kj31i60qr771.jpg" width="600"></p><p>3.选择 Python 3.6 的版本进行下载，因为 Python 2.7 不久之后很多开源库都不再继续支持，所以我们的整个课程都是基于 Python 3.6 开发的，请务必选择正确的 Python 版本，Python 3.6</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fp8zkhinhzj31i60r3400.jpg" width="600"></p><p>4.下载完成进行安装即可</p><h3 id="Jupyter-安装和环境配置"><a href="#Jupyter-安装和环境配置" class="headerlink" title="Jupyter 安装和环境配置"></a>Jupyter 安装和环境配置</h3><p>安装完成之后，liunx/mac 打开终端，windows打开 power shell，输入<code>jupyter notebook</code>就可以在浏览器打开交互的 notebook 环境，可以在里面运行代码</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fp8zmwu2fuj31880pogmh.jpg" width="700"></p><h3 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a>CUDA</h3><p>百度搜索 cuda，选择 CUDA Toolkit，进入 cuda 的官网，选择对应的操作系统进行下载</p><p>（注意 这里点进去直接是下载cuda9.1版本的，tensorflow 目前并不支持cuda9.1，我们可以从<a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-toolkit-archive</a>中找到适合的cuda版本，例如cuda9.0等等。</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1foalzdh3j2j31bi0ur0yh.jpg" width="500"></p><p>进入之后和后面即将介绍的安装过程相同）</p><p>看到下面可以进行的系统选择</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1foalzkfgnjj31i60jg782.jpg" width="700"></p><p>对于 cuda 的安装，不同的操作系统有着不同的安装方式，这里仅以 linux 环境举例（这是配置亚马逊云环境中的一部分），关于windows 的配置可以动手百度或者google，对于 mac 电脑，12 年之后就不再使用nvidia 的GPU，所以没有办法安装cuda。</p><p>建议使用云服务器或者安装 linux 双系统，可以省去很多麻烦，也有助于后期深度学习的开发。</p><p>选择 linux 对应的 cuda 下载</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1foam0d72vpj31cm1ms7q0.jpg" width="500"></p><p>在终端输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://developer.nvidia.com/compute/cuda/9.1/Prod/local_installers/cuda_9.1.85_387.26_linux</span><br></pre></td></tr></table></figure><p>下载最新的 cuda 9，然后输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bash cuda_9.1.85_387.26_linux</span><br></pre></td></tr></table></figure><p>进行安装，接下来需要回答一些问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">accept/decline/quit: accept</span><br><span class="line">Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 375.26?</span><br><span class="line">(y)es/(n)o/(q)uit: y</span><br><span class="line">Do you want to install the OpenGL libraries?</span><br><span class="line">(y)es/(n)o/(q)uit [ default is yes ]: y</span><br><span class="line">Do you want to run nvidia-xconfig?</span><br><span class="line">(y)es/(n)o/(q)uit [ default is no ]: n</span><br><span class="line">Install the CUDA 8.0 Toolkit?</span><br><span class="line">(y)es/(n)o/(q)uit: y</span><br><span class="line">Enter Toolkit Location</span><br><span class="line"> [ default is /usr/local/cuda-8.0 ]:</span><br><span class="line">Do you want to install a symbolic link at</span><br><span class="line">/usr/local/cuda?</span><br><span class="line">(y)es/(n)o/(q)uit: y</span><br><span class="line">Install the CUDA 8.0 Samples?</span><br><span class="line">(y)es/(n)o/(q)uit: n</span><br></pre></td></tr></table></figure><p>运行完成之后就安装成功了，可以在终端输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><p>查看GPU，最后我们需要将 cuda 添加在系统环境变量中方便以后的安装中找到</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"export LD_LIBRARY_PATH=\$&#123;LD_LIBRARY_PATH&#125;:/usr/local/cuda-9.1/lib64"</span> &gt;&gt;~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure><h3 id="深度学习框架-TensorFlow-和-PyTorch-安装"><a href="#深度学习框架-TensorFlow-和-PyTorch-安装" class="headerlink" title="深度学习框架 TensorFlow 和 PyTorch 安装"></a>深度学习框架 TensorFlow 和 PyTorch 安装</h3><h4 id="TensorFlow-安装"><a href="#TensorFlow-安装" class="headerlink" title="TensorFlow 安装"></a>TensorFlow 安装</h4><p>目前 Tensorflow 支持在 Linux, MacOS, Windows 系统下安装，有仅支持 CPU 的版本，在缺少 GPU 资源时是一个不错的选择，也有 GPU 版本的实现高性能 GPU 加速。</p><p>在安装 GPU 版本之前需要一些额外的环境</p><h4 id="libcupti-dev"><a href="#libcupti-dev" class="headerlink" title="libcupti-dev"></a>libcupti-dev</h4><p>一行命令即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install libcupti-dev</span><br></pre></td></tr></table></figure><h4 id="cudnn"><a href="#cudnn" class="headerlink" title="cudnn"></a>cudnn</h4><p>进入 <a href="https://developer.nvidia.com/cudnn，点击下载" target="_blank" rel="noopener">https://developer.nvidia.com/cudnn，点击下载</a></p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1foam0z0fykj319y0hxn7a.jpg" width="500"></p><p>会要求进行注册，点击 Join</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1foam18kpadj30ic09faa9.jpg" width="250"></p><p>然后填写关于你的一些信息就完成了注册。然后就可以打开 Download 出现下面的页面并选择下载压缩包</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1foam2cvftyj30qi0r5qaq.jpg" width="400"></p><p>解压后在当前目录运行下面命令即完成</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo cp cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/include</span><br><span class="line">$ sudo cp cuda/lib64/libcudnn* /usr/<span class="built_in">local</span>/cuda/lib64</span><br><span class="line">$ sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure><h4 id="安装-Tensorflow"><a href="#安装-Tensorflow" class="headerlink" title="安装 Tensorflow"></a>安装 Tensorflow</h4><p>到这里 Tensorflow 的安装就非常简单了，可以在系统中用 pip 也可以在 anaconda 虚拟环境中安装</p><ul><li><p>pip 安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 仅安装cpu版本 python2.x</span></span><br><span class="line">$ pip install tensorflow</span><br><span class="line"><span class="comment"># python3.x</span></span><br><span class="line">$ pip3 install tensorflow</span><br><span class="line"><span class="comment"># 安装gpu版本 python2.x</span></span><br><span class="line">$ pip install tensorflow-gpu</span><br><span class="line"><span class="comment"># python3.x</span></span><br><span class="line">$ pip3 install tensorflow-gpu</span><br></pre></td></tr></table></figure></li><li><p>anaconda安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 激活环境</span></span><br><span class="line"><span class="comment"># 下面的`$YOUR_ENV`替换成你自己的，没有的话要生成一个新的环境，可以参考下面注释的例子</span></span><br><span class="line"><span class="comment"># `conda create -n tensorflow pip python=2.7 # or python=3.3, etc.`</span></span><br><span class="line"><span class="comment"># 这样会构建一个名为 tensorflow，python 是2.7版本的虚拟环境</span></span><br><span class="line"><span class="comment"># 换名字很简单，换python版本的话也只需要将2.7改变即可，比如改变成3.6</span></span><br><span class="line">$ <span class="built_in">source</span> activate <span class="variable">$YOUR_ENV</span></span><br><span class="line"><span class="comment"># 在环境中安装tensorflow，注意这里的tfBinaryURL需要根据需求替换，后面详述</span></span><br><span class="line">(<span class="variable">$YOUR_ENV</span>)$ pip install --ignore-installed --upgrade tfBinaryURL</span><br></pre></td></tr></table></figure><p>tfBinaryURL 以在<a href="https://tensorflow.google.cn/install/install_linux#the_url_of_the_tensorflow_python_package选择" target="_blank" rel="noopener">https://tensorflow.google.cn/install/install_linux#the_url_of_the_tensorflow_python_package选择</a></p></li></ul><h4 id="验证安装"><a href="#验证安装" class="headerlink" title="验证安装"></a>验证安装</h4><p>终端中打开 python 解释器，运行下面命令成功即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Python</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">hello = tf.constant(<span class="string">'Hello, TensorFlow!'</span>)</span><br><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run(hello))</span><br></pre></td></tr></table></figure><h4 id="出现问题"><a href="#出现问题" class="headerlink" title="出现问题"></a>出现问题</h4><ul><li>更全面的 Tensorflow 安装页面 <a href="https://tensorflow.google.cn/install/" target="_blank" rel="noopener">https://tensorflow.google.cn/install/</a></li><li>检查硬件配置是否满足需求，GPU版本的 Tensorflow 需要计算能力在 3.5 及以上的显卡，可以在这里 <a href="https://developer.nvidia.com/cuda-gpus" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-gpus</a> 查到自己的显卡计算能力</li><li>在 Tensorflow 的 Github issues 里面寻找类似问题及解决方案</li></ul><h4 id="PyTorch-安装"><a href="#PyTorch-安装" class="headerlink" title="PyTorch 安装"></a>PyTorch 安装</h4><p>目前 PyTorch 官方只支持linux 和 MacOS，如果要查看 windows 的安装方法，请看后面。</p><p>在 linux 和 MacOS 这两个系统下进行安装非常的简单，访问到官网</p><p><a href="http://www.pytorch.org" target="_blank" rel="noopener">www.pytorch.org</a></p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1foam3kqe43j31i60ncn3m.jpg" width="700"></p><p>按照提示在终端输入命令行即可</p><h4 id="如何在-windows-下装-PyTorch"><a href="#如何在-windows-下装-PyTorch" class="headerlink" title="如何在 windows 下装 PyTorch"></a>如何在 windows 下装 PyTorch</h4><p>使用 windows 的同学可以访问这个链接查看如何在 windows 下面安装pytorch</p><p><a href="https://zhuanlan.zhihu.com/p/26871672" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/26871672</a></p><h4 id="验证安装-1"><a href="#验证安装-1" class="headerlink" title="验证安装"></a>验证安装</h4><p>终端中打开 python 解释器，运行下面命令成功即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Python</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.Tensor([<span class="number">3</span>])</span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># x_gpu = torch.Tensor([3]).cuda() # GPU 安装验证</span></span><br><span class="line"><span class="comment"># print(x)</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;DeepLearning-Environment&quot;&gt;&lt;a href=&quot;#DeepLearning-Environment&quot; class=&quot;headerlink&quot; title=&quot;DeepLearning-Environment&quot;&gt;&lt;/a&gt;DeepLearning-E
      
    
    </summary>
    
      <category term="Deep Learning" scheme="http://www.hcrlp.com/categories/Deep-Learning/"/>
    
    
      <category term="Basic" scheme="http://www.hcrlp.com/tags/Basic/"/>
    
  </entry>
  
  <entry>
    <title>开篇之作</title>
    <link href="http://www.hcrlp.com/2018/10/30/%E5%BC%80%E7%AF%87%E4%B9%8B%E4%BD%9C/"/>
    <id>http://www.hcrlp.com/2018/10/30/开篇之作/</id>
    <published>2018-10-30T09:02:06.000Z</published>
    <updated>2018-10-30T09:21:43.826Z</updated>
    
    <content type="html"><![CDATA[<p>漫漫的两天时间终于搭建好了这个个人主页，nothing to say，非常开心！哈哈哈！</p><p>Keep Working, keep Moving!</p><p><em>加油</em></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;漫漫的两天时间终于搭建好了这个个人主页，nothing to say，非常开心！哈哈哈！&lt;/p&gt;
&lt;p&gt;Keep Working, keep Moving!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;加油&lt;/em&gt;&lt;/p&gt;

      
    
    </summary>
    
      <category term="其他" scheme="http://www.hcrlp.com/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="随记" scheme="http://www.hcrlp.com/tags/%E9%9A%8F%E8%AE%B0/"/>
    
  </entry>
  
</feed>
