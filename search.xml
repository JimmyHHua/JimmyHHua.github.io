<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[语义分割-PSPNET]]></title>
    <url>%2F2018%2F11%2F29%2F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2-PSPNET%2F</url>
    <content type="text"><![CDATA[PSPNET: Pyramid Scene Parsing Network From : CVPR 2017(IEEE Conference on Computer Vision and Pattern Recognition) 代码： PSPnet-Keras-TensorFlow PSPnet-Pytorch 效果： 对比传统方法： Abstract本文提出的金字塔池化模块( pyramid pooling module)能够聚合不同区域的上下文信息,从而提高获取全局信息的能力。实验表明这样的先验表示(即指代PSP这个结构)是有效的，在多个数据集上展现了优良的效果。]]></content>
      <categories>
        <category>Segmentation</category>
      </categories>
      <tags>
        <tag>Paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch 参数初始化]]></title>
    <url>%2F2018%2F11%2F23%2FPytorch-%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Pytorch 提供了很多不同的参数初始化函数： torch.nn.init.constant_(tensor,val) torch.nn.init.normal_(tensor,mean=0,std=1) torch.nn.init.xavier_uniform_(tensor,gain=1) 更多的可以参考：http://pytorch.org/docs/nn.html#torch-nn-init 注意上面的初始化函数的参数tensor，虽然写的是tensor，但是也可以是Variable类型的。而神经网络的参数类型Parameter是Variable类的子类，所以初始化函数可以直接作用于神经网络参数。 示例：123self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)init.xavier_uniform_(self.conv1.weight)init.constant_(self.conv1.bias, 0.1) 上面的语句是对网络的某一层参数进行初始化。如何对整个网络的参数进行初始化定制呢？12345678910def xavier(parm): init.xavier_normal_(parm)def weights_init(m): classname=m.__class__.__name__ if classname.find('Conv') != -1: xavier(m.weight.data) xavier(m.bias.data)net = Net()net.apply(weights_init) #apply函数会递归地搜索网络内的所有module并把参数表示的函数应用到所有的module上 不建议访问以下划线为前缀的成员，他们是内部的，如果有改变不会通知用户。更推荐的一种方法是检查某个module是否是某种类型： 1234567def xavier(parm): init.xavier_normal_(parm)def weights_init(m): if isinstance(m, nn.Conv2d): xavier(m.weight.data) xavier(m.bias.data)]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231n学习笔记一：K近邻和图像分类]]></title>
    <url>%2F2018%2F11%2F08%2FCS231n%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80%EF%BC%9AK%E8%BF%91%E9%82%BB%E5%92%8C%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[图像分类1. 概述：目标：所谓图像分类问题，就是已有固定的分类标签集合，然后对于输入的图像，从分类标签集合中找出一个分类标签，最后把分类标签分配给该输入图像。虽然看起来挺简单的，但这可是计算机视觉领域的核心问题之一，并且有着各种各样的实际应用。在后面的课程中，我们可以看到计算机视觉领域中很多看似不同的问题（比如物体检测和分割），都可以被归结为图像分类问题。 例子：以下图为例，图像分类模型读取该图片，并生成该图片属于集合 {cat, dog, hat, mug}中各个标签的概率。需要注意的是，对于计算机来说，图像是一个由数字组成的巨大的3维数组。在这个例子中，猫的图像大小是宽248像素，高400像素，有3个颜色通道，分别是红、绿和蓝（简称RGB）。如此，该图像就包含了248X400X3=297600个数字，每个数字都是在范围0-255之间的整型，其中0表示全黑，255表示全白。我们的任务就是把这些上百万的数字变成一个简单的标签，比如“猫”。 2. 困难和挑战：对于人来说，识别出一个像“猫”一样视觉概念是简单至极的，然而从计算机视觉算法的角度来看就值得深思了。我们在下面列举了计算机视觉算法在图像识别方面遇到的一些困难，要记住图像是以3维数组来表示的，数组中的元素是亮度值。 视角变化（Viewpoint variation）：同一个物体，摄像机可以从多个角度来展现。 大小变化（Scale variation）：物体可视的大小通常是会变化的（不仅是在图片中，在真实世界中大小也是变化的）。 形变（Deformation）：很多东西的形状并非一成不变，会有很大变化。 遮挡（Occlusion）：目标物体可能被挡住。有时候只有物体的一小部分（可以小到几个像素）是可见的。 光照条件（Illumination conditions）：在像素层面上，光照的影响非常大。 背景干扰（Background clutter）：物体可能混入背景之中，使之难以被辨认。 类内差异（Intra-class variation）：一类物体的个体之间的外形差异很大，比如椅子。这一类物体有许多不同的对象，每个都有自己的外形。面对以上所有变化及其组合，好的图像分类模型能够在维持分类结论稳定的同时，保持对类间差异足够敏感。 Nearest Neighbor分类器L1 距离：针对CIFAR-10数据集，图片都是32x32x3的像素块，最简单的方法就是逐个像素比较，最后将差异值全部加起来。换句话说，就是将两张图片先转化为两个向量I_1和I_2，然后计算他们的L1距离： 可以通过下面的流程更清楚表示： 下面，让我们看看如何用代码来实现这个分类器。首先，我们将CIFAR-10的数据加载到内存中，并分成4个数组：训练数据和标签，测试数据和标签。在下面的代码中，Xtr（大小是50000x32x32x3）存有训练集中所有的图像，Ytr是对应的长度为50000的1维数组，存有图像对应的分类标签（从0到9）：1234Xtr, Ytr, Xte, Yte = load_CIFAR10('data/cifar10/') # a magic function we provide# flatten out all images to be one-dimensionalXtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Xtr_rows becomes 50000 x 3072Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows becomes 10000 x 3072 现在我们得到所有的图像数据，并且把他们拉长成为行向量了。接下来展示如何训练并评价一个分类器：123456nn = NearestNeighbor() # create a Nearest Neighbor classifier classnn.train(Xtr_rows, Ytr) # train the classifier on the training images and labelsYte_predict = nn.predict(Xte_rows) # predict labels on the test images# and now print the classification accuracy, which is the average number# of examples that are correctly predicted (i.e. label matches)print 'accuracy: %f' % ( np.mean(Yte_predict == Yte) ) 作为评价标准，我们常常使用准确率，它描述了我们预测正确的得分。请注意以后我们实现的所有分类器都需要有这个API：train(X, y)函数。该函数使用训练集的数据和标签来进行训练。从其内部来看，类应该实现一些关于标签和标签如何被预测的模型。这里还有个predict(X)函数，它的作用是预测输入的新数据的分类标签。现在还没介绍分类器的实现，下面就是使用L1距离的Nearest Neighbor分类器的实现套路：123456789101112131415161718192021222324252627import numpy as npclass NearestNeighbor(object): def __init__(self): pass def train(self, X, y): """ X is N x D where each row is an example. Y is 1-dimension of size N """ # the nearest neighbor classifier simply remembers all the training data self.Xtr = X self.ytr = y def predict(self, X): """ X is N x D where each row is an example we wish to predict label for """ num_test = X.shape[0] # lets make sure that the output type matches the input type Ypred = np.zeros(num_test, dtype = self.ytr.dtype) # loop over all test rows for i in xrange(num_test): # find the nearest training image to the i'th test image # using the L1 distance (sum of absolute value differences) distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1) min_index = np.argmin(distances) # get the index with smallest distance Ypred[i] = self.ytr[min_index] # predict the label of the nearest example return Ypred L2 距离：L2的距离公式为： ,所以我们在Numpy中，我们只需要替换上面代码中的1行代码就行：1distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = 1)) k-Nearest Neighbor分类器概念：相对于传统的 NN 方法，只找最相近的那1个图片的标签，我们也可以找最相似的k个图片的标签，然后让他们针对测试图片进行投票，最后把票数最高的标签作为对测试图片的预测。所以当k=1的时候，k-Nearest Neighbor分类器就是Nearest Neighbor分类器。从直观感受上就可以看到，更高的k值可以让分类的效果更平滑，使得分类器对于异常值更有抵抗力。 PS: 在NN分类器中，异常的数据点（比如：在蓝色区域中的绿点）制造出一个不正确预测的孤岛。5-NN分类器将这些不规则都平滑了，使得它针对测试数据的泛化（generalization）能力更好（例子中未展示）。注意，5-NN中也存在一些灰色区域，这些区域是因为近邻标签的最高票数相同导致的（比如：2个邻居是红色，2个邻居是蓝色，还有1个是绿色）。 验证数据集当你在设计机器学习算法的时候，应该把测试集看做非常珍贵的资源，不到最后一步，绝不使用它。如果你使用测试集来调优，而且算法看起来效果不错，那么真正的危险在于：算法实际部署后，性能可能会远低于预期。这种情况，称之为算法对测试集过拟合。从另一个角度来说，如果使用测试集来调优，实际上就是把测试集当做训练集，由测试集训练出来的算法再跑测试集，自然性能看起来会很好。这其实是过于乐观了，实际部署起来效果就会差很多。所以，最终测试的时候再使用测试集，可以很好地近似度量你所设计的分类器的泛化性能 测试数据集只使用一次，即在训练完成后评价最终的模型时使用。 思路是：从训练集中取出一部分数据用来调优，我们称之为验证集（validation set）。以CIFAR-10为例，我们可以用49000个图像作为训练集，用1000个图像作为验证集。验证集其实就是作为假的测试集来调优。下面就是代码：123456789101112131415161718192021# assume we have Xtr_rows, Ytr, Xte_rows, Yte as before# recall Xtr_rows is 50,000 x 3072 matrixXval_rows = Xtr_rows[:1000, :] # take first 1000 for validationYval = Ytr[:1000]Xtr_rows = Xtr_rows[1000:, :] # keep last 49,000 for trainYtr = Ytr[1000:]# find hyperparameters that work best on the validation setvalidation_accuracies = []for k in [1, 3, 5, 10, 20, 50, 100]: # use a particular value of k and evaluation on validation data nn = NearestNeighbor() nn.train(Xtr_rows, Ytr) # here we assume a modified NearestNeighbor class that can take a k as input Yval_predict = nn.predict(Xval_rows, k = k) acc = np.mean(Yval_predict == Yval) print 'accuracy: %f' % (acc,) # keep track of what works on the validation set validation_accuracies.append((k, acc)) 程序结束后，我们会作图分析出哪个k值表现最好，然后用这个k值来跑真正的测试集，并作出对算法的评价。 把训练集分成训练集和验证集。使用验证集来对所有超参数调优。最后只在测试集上跑一次并报告结果。 —————————————————————————————————————————交叉验证：有时候，训练集数量较小（因此验证集的数量更小），人们会使用一种被称为交叉验证的方法，这种方法更加复杂些。还是用刚才的例子，如果是交叉验证集，我们就不是取1000个图像，而是将训练集平均分成5份，其中4份用来训练，1份用来验证。然后我们循环着取其中4份来训练，其中1份来验证，最后取所有5次验证结果的平均值作为算法验证结果。 这就是5份交叉验证对k值调优的例子。针对每个k值，得到5个准确率结果，取其平均值，然后对不同k值的平均表现画线连接。本例中，当k=7的时算法表现最好（对应图中的准确率峰值）。如果我们将训练集分成更多份数，直线一般会更加平滑（噪音更少）。 ————————————————————————————————————————— 实际应用。在实际情况下，人们不是很喜欢用交叉验证，主要是因为它会耗费较多的计算资源。一般直接把训练集按照50%-90%的比例分成训练集和验证集。但这也是根据具体情况来定的：如果超参数数量多，你可能就想用更大的验证集，而验证集的数量不够，那么最好还是用交叉验证吧。至于分成几份比较好，一般都是分成3、5和10份。 常用的数据分割模式。给出训练集和测试集后，训练集一般会被均分。这里是分成5份。前面4份用来训练，黄色那份用作验证集调优。如果采取交叉验证，那就各份轮流作为验证集。最后模型训练完毕，超参数都定好了，让模型跑一次（而且只跑一次）测试集，以此测试结果评价算法。 ————————————————————————————————————————— 小结简要说来： 介绍了图像分类问题。在该问题中，给出一个由被标注了分类标签的图像组成的集合，要求算法能预测没有标签的图像的分类标签，并根据算法预测准确率进行评价。 介绍了一个简单的图像分类器：最近邻分类器(Nearest Neighbor classifier)。分类器中存在不同的超参数(比如k值或距离类型的选取)，要想选取好的超参数不是一件轻而易举的事。 选取超参数的正确方法是：将原始训练集分为训练集和验证集，我们在验证集上尝试不同的超参数，最后保留表现最好那个。 如果训练数据量不够，使用交叉验证方法，它能帮助我们在选取最优超参数的时候减少噪音。 一旦找到最优的超参数，就让算法以该参数在测试集跑且只跑一次，并根据测试结果评价算法。 最近邻分类器能够在CIFAR-10上得到将近40%的准确率。该算法简单易实现，但需要存储所有训练数据，并且在测试的时候过于耗费计算能力。 最后，我们知道了仅仅使用L1和L2范数来进行像素比较是不够的，图像更多的是按照背景和颜色被分类，而不是语义主体分身。]]></content>
      <categories>
        <category>Computer vision</category>
      </categories>
      <tags>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习环境搭建]]></title>
    <url>%2F2018%2F10%2F31%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[DeepLearning-EnvironmentPythonPython 能够使用各种各样的开发环境，这里我们强烈推荐使用 Anaconda 来进行Python 环境的管理，当然如果你有自己偏好的 Python 环境管理方式，你完全可以使用自己更喜欢的方式。 1.登录 Anaconda 的官网 www.anaconda.com，选择下载 2.选择对应的操作系统 3.选择 Python 3.6 的版本进行下载，因为 Python 2.7 不久之后很多开源库都不再继续支持，所以我们的整个课程都是基于 Python 3.6 开发的，请务必选择正确的 Python 版本，Python 3.6 4.下载完成进行安装即可 Jupyter 安装和环境配置安装完成之后，liunx/mac 打开终端，windows打开 power shell，输入jupyter notebook就可以在浏览器打开交互的 notebook 环境，可以在里面运行代码 CUDA百度搜索 cuda，选择 CUDA Toolkit，进入 cuda 的官网，选择对应的操作系统进行下载 （注意 这里点进去直接是下载cuda9.1版本的，tensorflow 目前并不支持cuda9.1，我们可以从https://developer.nvidia.com/cuda-toolkit-archive中找到适合的cuda版本，例如cuda9.0等等。 进入之后和后面即将介绍的安装过程相同） 看到下面可以进行的系统选择 对于 cuda 的安装，不同的操作系统有着不同的安装方式，这里仅以 linux 环境举例（这是配置亚马逊云环境中的一部分），关于windows 的配置可以动手百度或者google，对于 mac 电脑，12 年之后就不再使用nvidia 的GPU，所以没有办法安装cuda。 建议使用云服务器或者安装 linux 双系统，可以省去很多麻烦，也有助于后期深度学习的开发。 选择 linux 对应的 cuda 下载 在终端输入 1$ wget https://developer.nvidia.com/compute/cuda/9.1/Prod/local_installers/cuda_9.1.85_387.26_linux 下载最新的 cuda 9，然后输入 1$ bash cuda_9.1.85_387.26_linux 进行安装，接下来需要回答一些问题 12345678910111213141516accept/decline/quit: acceptInstall NVIDIA Accelerated Graphics Driver for Linux-x86_64 375.26?(y)es/(n)o/(q)uit: yDo you want to install the OpenGL libraries?(y)es/(n)o/(q)uit [ default is yes ]: yDo you want to run nvidia-xconfig?(y)es/(n)o/(q)uit [ default is no ]: nInstall the CUDA 8.0 Toolkit?(y)es/(n)o/(q)uit: yEnter Toolkit Location [ default is /usr/local/cuda-8.0 ]:Do you want to install a symbolic link at/usr/local/cuda?(y)es/(n)o/(q)uit: yInstall the CUDA 8.0 Samples?(y)es/(n)o/(q)uit: n 运行完成之后就安装成功了，可以在终端输入 1nvidia-smi 查看GPU，最后我们需要将 cuda 添加在系统环境变量中方便以后的安装中找到 12echo "export LD_LIBRARY_PATH=\$&#123;LD_LIBRARY_PATH&#125;:/usr/local/cuda-9.1/lib64" &gt;&gt;~/.bashrcsource ~/.bashrc 深度学习框架 TensorFlow 和 PyTorch 安装TensorFlow 安装目前 Tensorflow 支持在 Linux, MacOS, Windows 系统下安装，有仅支持 CPU 的版本，在缺少 GPU 资源时是一个不错的选择，也有 GPU 版本的实现高性能 GPU 加速。 在安装 GPU 版本之前需要一些额外的环境 libcupti-dev一行命令即可 1$ sudo apt-get install libcupti-dev cudnn进入 https://developer.nvidia.com/cudnn，点击下载 会要求进行注册，点击 Join 然后填写关于你的一些信息就完成了注册。然后就可以打开 Download 出现下面的页面并选择下载压缩包 解压后在当前目录运行下面命令即完成 123$ sudo cp cuda/include/cudnn.h /usr/local/cuda/include$ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64$ sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* 安装 Tensorflow到这里 Tensorflow 的安装就非常简单了，可以在系统中用 pip 也可以在 anaconda 虚拟环境中安装 pip 安装 12345678# 仅安装cpu版本 python2.x$ pip install tensorflow# python3.x$ pip3 install tensorflow# 安装gpu版本 python2.x$ pip install tensorflow-gpu# python3.x$ pip3 install tensorflow-gpu anaconda安装 12345678# 激活环境# 下面的`$YOUR_ENV`替换成你自己的，没有的话要生成一个新的环境，可以参考下面注释的例子# `conda create -n tensorflow pip python=2.7 # or python=3.3, etc.`# 这样会构建一个名为 tensorflow，python 是2.7版本的虚拟环境# 换名字很简单，换python版本的话也只需要将2.7改变即可，比如改变成3.6$ source activate $YOUR_ENV# 在环境中安装tensorflow，注意这里的tfBinaryURL需要根据需求替换，后面详述($YOUR_ENV)$ pip install --ignore-installed --upgrade tfBinaryURL tfBinaryURL 以在https://tensorflow.google.cn/install/install_linux#the_url_of_the_tensorflow_python_package选择 验证安装终端中打开 python 解释器，运行下面命令成功即可 12345# Pythonimport tensorflow as tfhello = tf.constant('Hello, TensorFlow!')sess = tf.Session()print(sess.run(hello)) 出现问题 更全面的 Tensorflow 安装页面 https://tensorflow.google.cn/install/ 检查硬件配置是否满足需求，GPU版本的 Tensorflow 需要计算能力在 3.5 及以上的显卡，可以在这里 https://developer.nvidia.com/cuda-gpus 查到自己的显卡计算能力 在 Tensorflow 的 Github issues 里面寻找类似问题及解决方案 PyTorch 安装目前 PyTorch 官方只支持linux 和 MacOS，如果要查看 windows 的安装方法，请看后面。 在 linux 和 MacOS 这两个系统下进行安装非常的简单，访问到官网 www.pytorch.org 按照提示在终端输入命令行即可 如何在 windows 下装 PyTorch使用 windows 的同学可以访问这个链接查看如何在 windows 下面安装pytorch https://zhuanlan.zhihu.com/p/26871672 验证安装终端中打开 python 解释器，运行下面命令成功即可 123456# Pythonimport torchx = torch.Tensor([3])print(x)# x_gpu = torch.Tensor([3]).cuda() # GPU 安装验证# print(x)]]></content>
      <categories>
        <category>Deep learning</category>
      </categories>
      <tags>
        <tag>Basic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开篇之作]]></title>
    <url>%2F2018%2F10%2F30%2F%E5%BC%80%E7%AF%87%E4%B9%8B%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[漫漫的两天时间终于搭建好了这个个人主页，nothing to say，非常开心！哈哈哈！ Keep Working, keep Moving! 加油]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>随记</tag>
      </tags>
  </entry>
</search>
